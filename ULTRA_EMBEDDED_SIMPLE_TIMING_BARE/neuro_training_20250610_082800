eigke@Heigke:~/Dokument/TAIF_ADVANIA/DRAM_research/DRAM_WRITE_READ_SERIAL/ULTRA_EMBEDDED_SIMPLE_TIMING_BARE$ python NEURODRAM_TRAINING_v2.py 
ğŸ”Œ Connecting to DDR3 controller on /dev/ttyUSB1...
âœ“ Connected @ 115200 baud

ğŸ”§ Initializing DDR3 Controller...
âœ“ DDR3 Controller Ready!

Weight allocation:
  Inputâ†’Hidden weights: 16 addresses
  Hiddenâ†’Output weights: 8 addresses

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                                â•‘
â•‘  â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•—  â•‘
â•‘  â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘  â•‘
â•‘  â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘  â•‘
â•‘  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â•‘
â•‘  â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘  â•‘
â•‘  â•šâ•â•  â•šâ•â•â•â•â•šâ•â•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•     â•šâ•â•  â•‘
â•‘                                                                                â•‘
â•‘              Neuromorphic DRAM Learning Network v1.0                           â•‘
â•‘           "Teaching Silicon to Think with Analog Memory"                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


ğŸ§  Initializing Neuromorphic DRAM Network...
   â€¢ Input neurons: 4
   â€¢ Hidden neurons: 4
   â€¢ Output neurons: 2
   â€¢ Using threshold behavior at burst=3
   â€¢ Training patterns: 4

Initializing synaptic weights...
âœ“ Weights initialized

Network State Visualization:

     INPUT           HIDDEN          OUTPUT
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚    â—‹    â”‚  â•â•â•ªâ•â•  â”‚    â—‹    â”‚  â•â•â•ªâ•â•  â”‚    â—    â”‚
   â”‚    â—‹    â”‚  â•â•â•ªâ•â•  â”‚    â—‹    â”‚  â•â•â•ªâ•â•  â”‚    â—    â”‚
   â”‚    â—‹    â”‚  â•â•â•ªâ•â•  â”‚    â—‹    â”‚  â•â•â•ªâ•â•  â”‚         â”‚
   â”‚    â—‹    â”‚  â•â•â•ªâ•â•  â”‚    â—‹    â”‚  â•â•â•ªâ•â•  â”‚         â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   â—‰ Active (>80%)  â— Partial (30-80%)  â—‹ Inactive (<30%)

ğŸ¯ Starting training...

================================================================================
EPOCH 1
================================================================================

Pattern 1: [0, 0, 0, 0] â†’ [0, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:0.1 N2:0.1 N3:0.1 
  Computing hidden layer:
    H0: input=0.19 â†’ activation=0.06
    H1: input=0.19 â†’ activation=0.06
    H2: input=0.07 â†’ activation=0.06
    H3: input=0.19 â†’ activation=0.06
  Computing output layer:
    O0: input=0.13 â†’ activation=0.06
    O1: input=0.13 â†’ activation=0.06

  Target: [0, 0]
  Output: [0.06, 0.06]
  Error: 0.125

  Updating weights...

Pattern 2: [1, 0, 1, 0] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:0.1 N2:1.0 N3:0.1 
  Computing hidden layer:
    H0: input=1.19 â†’ activation=1.00
    H1: input=1.19 â†’ activation=1.00
    H2: input=0.19 â†’ activation=0.06
    H3: input=1.19 â†’ activation=1.00
  Computing output layer:
    O0: input=2.07 â†’ activation=1.00
    O1: input=2.07 â†’ activation=1.00

  Target: [1, 0]
  Output: [1.00, 1.00]
  Error: 1.000

  Updating weights...
    â†“ H0â†’O1 weakened
    â†“ H1â†’O1 weakened
    â†“ H2â†’O1 weakened
    â†“ H3â†’O1 weakened

Pattern 3: [0, 1, 0, 1] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:1.0 N2:0.1 N3:1.0 
  Computing hidden layer:
    H0: input=2.07 â†’ activation=1.00
    H1: input=2.01 â†’ activation=1.00
    H2: input=1.07 â†’ activation=1.00
    H3: input=2.07 â†’ activation=1.00
  Computing output layer:
    O0: input=2.12 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [1, 0]
  Output: [1.00, 0.06]
  Error: 0.062

Pattern 4: [1, 1, 1, 1] â†’ [0, 1]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:1.0 N2:1.0 N3:1.0 
  Computing hidden layer:
    H0: input=3.06 â†’ activation=1.00
    H1: input=2.12 â†’ activation=1.00
    H2: input=1.19 â†’ activation=1.00
    H3: input=3.06 â†’ activation=1.00
  Computing output layer:
    O0: input=2.12 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 1]
  Output: [1.00, 0.06]
  Error: 1.938

  Updating weights...
    â†“ H0â†’O0 weakened
    â†“ H1â†’O0 weakened
    â†“ H2â†’O0 weakened
    â†“ H3â†’O0 weakened
    â†‘ H0â†’O1 strengthened
    â†‘ H1â†’O1 strengthened
    â†‘ H2â†’O1 strengthened
    â†‘ H3â†’O1 strengthened

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Epoch 1 Summary
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Average Error: 0.781
Learning Progress: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 21.9%

================================================================================
EPOCH 2
================================================================================

Pattern 1: [0, 0, 0, 0] â†’ [0, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:0.1 N2:0.1 N3:0.1 
  Computing hidden layer:
    H0: input=0.13 â†’ activation=0.06
    H1: input=0.13 â†’ activation=0.06
    H2: input=0.19 â†’ activation=0.06
    H3: input=0.19 â†’ activation=0.06
  Computing output layer:
    O0: input=0.02 â†’ activation=0.06
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 0]
  Output: [0.06, 0.06]
  Error: 0.125

  Updating weights...

Pattern 2: [1, 0, 1, 0] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:0.1 N2:1.0 N3:0.1 
  Computing hidden layer:
    H0: input=1.13 â†’ activation=1.00
    H1: input=0.25 â†’ activation=0.06
    H2: input=1.19 â†’ activation=1.00
    H3: input=2.07 â†’ activation=1.00
  Computing output layer:
    O0: input=0.19 â†’ activation=0.06
    O1: input=3.06 â†’ activation=1.00

  Target: [1, 0]
  Output: [0.06, 1.00]
  Error: 1.938

  Updating weights...
    â†‘ H0â†’O0 strengthened
    â†‘ H1â†’O0 strengthened
    â†‘ H2â†’O0 strengthened
    â†‘ H3â†’O0 strengthened
    â†“ H0â†’O1 weakened
    â†“ H1â†’O1 weakened
    â†“ H2â†’O1 weakened
    â†“ H3â†’O1 weakened

Pattern 3: [0, 1, 0, 1] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:1.0 N2:0.1 N3:1.0 
  Computing hidden layer:
    H0: input=1.13 â†’ activation=1.00
    H1: input=2.01 â†’ activation=1.00
    H2: input=2.07 â†’ activation=1.00
    H3: input=1.13 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [1, 0]
  Output: [1.00, 0.06]
  Error: 0.062

Pattern 4: [1, 1, 1, 1] â†’ [0, 1]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:1.0 N2:1.0 N3:1.0 
  Computing hidden layer:
    H0: input=2.12 â†’ activation=1.00
    H1: input=2.12 â†’ activation=1.00
    H2: input=3.06 â†’ activation=1.00
    H3: input=2.12 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 1]
  Output: [1.00, 0.06]
  Error: 1.938

  Updating weights...
    â†“ H0â†’O0 weakened
    â†“ H1â†’O0 weakened
    â†“ H2â†’O0 weakened
    â†“ H3â†’O0 weakened
    â†‘ H0â†’O1 strengthened
    â†‘ H1â†’O1 strengthened
    â†‘ H2â†’O1 strengthened
    â†‘ H3â†’O1 strengthened

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Epoch 2 Summary
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Average Error: 1.016
Learning Progress: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.0%

================================================================================
EPOCH 3
================================================================================

Pattern 1: [0, 0, 0, 0] â†’ [0, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:0.1 N2:0.1 N3:0.1 
  Computing hidden layer:
    H0: input=0.19 â†’ activation=0.06
    H1: input=0.13 â†’ activation=0.06
    H2: input=0.19 â†’ activation=0.06
    H3: input=0.19 â†’ activation=0.06
  Computing output layer:
    O0: input=0.02 â†’ activation=0.06
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 0]
  Output: [0.06, 0.06]
  Error: 0.125

  Updating weights...

Pattern 2: [1, 0, 1, 0] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:0.1 N2:1.0 N3:0.1 
  Computing hidden layer:
    H0: input=2.07 â†’ activation=1.00
    H1: input=0.25 â†’ activation=0.06
    H2: input=1.19 â†’ activation=1.00
    H3: input=1.19 â†’ activation=1.00
  Computing output layer:
    O0: input=0.19 â†’ activation=0.06
    O1: input=3.06 â†’ activation=1.00

  Target: [1, 0]
  Output: [0.06, 1.00]
  Error: 1.938

  Updating weights...
    â†‘ H0â†’O0 strengthened
    â†‘ H1â†’O0 strengthened
    â†‘ H2â†’O0 strengthened
    â†‘ H3â†’O0 strengthened
    â†“ H0â†’O1 weakened
    â†“ H1â†’O1 weakened
    â†“ H2â†’O1 weakened
    â†“ H3â†’O1 weakened

Pattern 3: [0, 1, 0, 1] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:1.0 N2:0.1 N3:1.0 
  Computing hidden layer:
    H0: input=1.07 â†’ activation=1.00
    H1: input=2.07 â†’ activation=1.00
    H2: input=2.01 â†’ activation=1.00
    H3: input=2.01 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [1, 0]
  Output: [1.00, 0.06]
  Error: 0.062

Pattern 4: [1, 1, 1, 1] â†’ [0, 1]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:1.0 N2:1.0 N3:1.0 
  Computing hidden layer:
    H0: input=1.19 â†’ activation=1.00
    H1: input=3.06 â†’ activation=1.00
    H2: input=2.12 â†’ activation=1.00
    H3: input=2.12 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 1]
  Output: [1.00, 0.06]
  Error: 1.938

  Updating weights...
    â†“ H0â†’O0 weakened
    â†“ H1â†’O0 weakened
    â†“ H2â†’O0 weakened
    â†“ H3â†’O0 weakened
    â†‘ H0â†’O1 strengthened
    â†‘ H1â†’O1 strengthened
    â†‘ H2â†’O1 strengthened
    â†‘ H3â†’O1 strengthened

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Epoch 3 Summary
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Average Error: 1.016
Learning Progress: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.0%

================================================================================
EPOCH 4
================================================================================

Pattern 1: [0, 0, 0, 0] â†’ [0, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:0.1 N2:0.1 N3:0.1 
  Computing hidden layer:
    H0: input=0.13 â†’ activation=0.06
    H1: input=0.07 â†’ activation=0.06
    H2: input=0.19 â†’ activation=0.06
    H3: input=0.13 â†’ activation=0.06
  Computing output layer:
    O0: input=0.02 â†’ activation=0.06
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 0]
  Output: [0.06, 0.06]
  Error: 0.125

  Updating weights...

Pattern 2: [1, 0, 1, 0] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:0.1 N2:1.0 N3:0.1 
  Computing hidden layer:
    H0: input=1.13 â†’ activation=1.00
    H1: input=1.07 â†’ activation=1.00
    H2: input=2.07 â†’ activation=1.00
    H3: input=1.13 â†’ activation=1.00
  Computing output layer:
    O0: input=0.25 â†’ activation=0.06
    O1: input=4.00 â†’ activation=1.00

  Target: [1, 0]
  Output: [0.06, 1.00]
  Error: 1.938

  Updating weights...
    â†‘ H0â†’O0 strengthened
    â†‘ H1â†’O0 strengthened
    â†‘ H2â†’O0 strengthened
    â†‘ H3â†’O0 strengthened
    â†“ H0â†’O1 weakened
    â†“ H1â†’O1 weakened
    â†“ H2â†’O1 weakened
    â†“ H3â†’O1 weakened

Pattern 3: [0, 1, 0, 1] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:1.0 N2:0.1 N3:1.0 
  Computing hidden layer:
    H0: input=1.13 â†’ activation=1.00
    H1: input=0.19 â†’ activation=0.06
    H2: input=1.13 â†’ activation=1.00
    H3: input=1.13 â†’ activation=1.00
  Computing output layer:
    O0: input=3.06 â†’ activation=1.00
    O1: input=0.19 â†’ activation=0.06

  Target: [1, 0]
  Output: [1.00, 0.06]
  Error: 0.062

Pattern 4: [1, 1, 1, 1] â†’ [0, 1]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:1.0 N2:1.0 N3:1.0 
  Computing hidden layer:
    H0: input=2.12 â†’ activation=1.00
    H1: input=1.19 â†’ activation=1.00
    H2: input=2.12 â†’ activation=1.00
    H3: input=2.12 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 1]
  Output: [1.00, 0.06]
  Error: 1.938

  Updating weights...
    â†“ H0â†’O0 weakened
    â†“ H1â†’O0 weakened
    â†“ H2â†’O0 weakened
    â†“ H3â†’O0 weakened
    â†‘ H0â†’O1 strengthened
    â†‘ H1â†’O1 strengthened
    â†‘ H2â†’O1 strengthened
    â†‘ H3â†’O1 strengthened

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Epoch 4 Summary
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Average Error: 1.016
Learning Progress: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.0%

================================================================================
EPOCH 5
================================================================================

Pattern 1: [0, 0, 0, 0] â†’ [0, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:0.1 N2:0.1 N3:0.1 
  Computing hidden layer:
    H0: input=0.19 â†’ activation=0.06
    H1: input=0.19 â†’ activation=0.06
    H2: input=0.25 â†’ activation=0.06
    H3: input=0.19 â†’ activation=0.06
  Computing output layer:
    O0: input=0.02 â†’ activation=0.06
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 0]
  Output: [0.06, 0.06]
  Error: 0.125

  Updating weights...

Pattern 2: [1, 0, 1, 0] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:0.1 N2:1.0 N3:0.1 
  Computing hidden layer:
    H0: input=2.07 â†’ activation=1.00
    H1: input=2.07 â†’ activation=1.00
    H2: input=2.12 â†’ activation=1.00
    H3: input=1.19 â†’ activation=1.00
  Computing output layer:
    O0: input=0.25 â†’ activation=0.06
    O1: input=4.00 â†’ activation=1.00

  Target: [1, 0]
  Output: [0.06, 1.00]
  Error: 1.938

  Updating weights...
    â†‘ H0â†’O0 strengthened
    â†‘ H1â†’O0 strengthened
    â†‘ H2â†’O0 strengthened
    â†‘ H3â†’O0 strengthened
    â†“ H0â†’O1 weakened
    â†“ H1â†’O1 weakened
    â†“ H2â†’O1 weakened
    â†“ H3â†’O1 weakened

Pattern 3: [0, 1, 0, 1] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:1.0 N2:0.1 N3:1.0 
  Computing hidden layer:
    H0: input=1.07 â†’ activation=1.00
    H1: input=1.13 â†’ activation=1.00
    H2: input=2.07 â†’ activation=1.00
    H3: input=2.01 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [1, 0]
  Output: [1.00, 0.06]
  Error: 0.062

Pattern 4: [1, 1, 1, 1] â†’ [0, 1]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:1.0 N2:1.0 N3:1.0 
  Computing hidden layer:
    H0: input=1.19 â†’ activation=1.00
    H1: input=2.12 â†’ activation=1.00
    H2: input=3.06 â†’ activation=1.00
    H3: input=2.12 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 1]
  Output: [1.00, 0.06]
  Error: 1.938

  Updating weights...
    â†“ H0â†’O0 weakened
    â†“ H1â†’O0 weakened
    â†“ H2â†’O0 weakened
    â†“ H3â†’O0 weakened
    â†‘ H0â†’O1 strengthened
    â†‘ H1â†’O1 strengthened
    â†‘ H2â†’O1 strengthened
    â†‘ H3â†’O1 strengthened

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Epoch 5 Summary
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Average Error: 1.016
Learning Progress: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.0%

Network State Visualization:

     INPUT           HIDDEN          OUTPUT
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‰    â”‚
   â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‹    â”‚
   â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚         â”‚
   â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚         â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   â—‰ Active (>80%)  â— Partial (30-80%)  â—‹ Inactive (<30%)

================================================================================
EPOCH 6
================================================================================

Pattern 1: [0, 0, 0, 0] â†’ [0, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:0.1 N2:0.1 N3:0.1 
  Computing hidden layer:
    H0: input=0.19 â†’ activation=0.06
    H1: input=0.25 â†’ activation=0.06
    H2: input=0.19 â†’ activation=0.06
    H3: input=0.13 â†’ activation=0.06
  Computing output layer:
    O0: input=0.02 â†’ activation=0.06
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 0]
  Output: [0.06, 0.06]
  Error: 0.125

  Updating weights...

Pattern 2: [1, 0, 1, 0] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:0.1 N2:1.0 N3:0.1 
  Computing hidden layer:
    H0: input=2.07 â†’ activation=1.00
    H1: input=2.12 â†’ activation=1.00
    H2: input=1.19 â†’ activation=1.00
    H3: input=1.13 â†’ activation=1.00
  Computing output layer:
    O0: input=0.25 â†’ activation=0.06
    O1: input=4.00 â†’ activation=1.00

  Target: [1, 0]
  Output: [0.06, 1.00]
  Error: 1.938

  Updating weights...
    â†‘ H0â†’O0 strengthened
    â†‘ H1â†’O0 strengthened
    â†‘ H2â†’O0 strengthened
    â†‘ H3â†’O0 strengthened
    â†“ H0â†’O1 weakened
    â†“ H1â†’O1 weakened
    â†“ H2â†’O1 weakened
    â†“ H3â†’O1 weakened

Pattern 3: [0, 1, 0, 1] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:1.0 N2:0.1 N3:1.0 
  Computing hidden layer:
    H0: input=1.07 â†’ activation=1.00
    H1: input=2.01 â†’ activation=1.00
    H2: input=2.01 â†’ activation=1.00
    H3: input=1.07 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [1, 0]
  Output: [1.00, 0.06]
  Error: 0.062

Pattern 4: [1, 1, 1, 1] â†’ [0, 1]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:1.0 N2:1.0 N3:1.0 
  Computing hidden layer:
    H0: input=1.19 â†’ activation=1.00
    H1: input=2.12 â†’ activation=1.00
    H2: input=2.12 â†’ activation=1.00
    H3: input=1.19 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 1]
  Output: [1.00, 0.06]
  Error: 1.938

  Updating weights...
    â†“ H0â†’O0 weakened
    â†“ H1â†’O0 weakened
    â†“ H2â†’O0 weakened
    â†“ H3â†’O0 weakened
    â†‘ H0â†’O1 strengthened
    â†‘ H1â†’O1 strengthened
    â†‘ H2â†’O1 strengthened
    â†‘ H3â†’O1 strengthened

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Epoch 6 Summary
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Average Error: 1.016
Learning Progress: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.0%

================================================================================
EPOCH 7
================================================================================

Pattern 1: [0, 0, 0, 0] â†’ [0, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:0.1 N2:0.1 N3:0.1 
  Computing hidden layer:
    H0: input=0.19 â†’ activation=0.06
    H1: input=0.19 â†’ activation=0.06
    H2: input=0.25 â†’ activation=0.06
    H3: input=0.25 â†’ activation=0.06
  Computing output layer:
    O0: input=0.02 â†’ activation=0.06
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 0]
  Output: [0.06, 0.06]
  Error: 0.125

  Updating weights...

Pattern 2: [1, 0, 1, 0] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:0.1 N2:1.0 N3:0.1 
  Computing hidden layer:
    H0: input=1.19 â†’ activation=1.00
    H1: input=1.19 â†’ activation=1.00
    H2: input=2.12 â†’ activation=1.00
    H3: input=2.12 â†’ activation=1.00
  Computing output layer:
    O0: input=0.25 â†’ activation=0.06
    O1: input=4.00 â†’ activation=1.00

  Target: [1, 0]
  Output: [0.06, 1.00]
  Error: 1.938

  Updating weights...
    â†‘ H0â†’O0 strengthened
    â†‘ H1â†’O0 strengthened
    â†‘ H2â†’O0 strengthened
    â†‘ H3â†’O0 strengthened
    â†“ H0â†’O1 weakened
    â†“ H1â†’O1 weakened
    â†“ H2â†’O1 weakened
    â†“ H3â†’O1 weakened

Pattern 3: [0, 1, 0, 1] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:1.0 N2:0.1 N3:1.0 
  Computing hidden layer:
    H0: input=2.01 â†’ activation=1.00
    H1: input=2.01 â†’ activation=1.00
    H2: input=2.07 â†’ activation=1.00
    H3: input=2.07 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [1, 0]
  Output: [1.00, 0.06]
  Error: 0.062

Pattern 4: [1, 1, 1, 1] â†’ [0, 1]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:1.0 N2:1.0 N3:1.0 
  Computing hidden layer:
    H0: input=2.12 â†’ activation=1.00
    H1: input=2.12 â†’ activation=1.00
    H2: input=3.06 â†’ activation=1.00
    H3: input=3.06 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 1]
  Output: [1.00, 0.06]
  Error: 1.938

  Updating weights...
    â†“ H0â†’O0 weakened
    â†“ H1â†’O0 weakened
    â†“ H2â†’O0 weakened
    â†“ H3â†’O0 weakened
    â†‘ H0â†’O1 strengthened
    â†‘ H1â†’O1 strengthened
    â†‘ H2â†’O1 strengthened
    â†‘ H3â†’O1 strengthened

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Epoch 7 Summary
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Average Error: 1.016
Learning Progress: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.0%

================================================================================
EPOCH 8
================================================================================

Pattern 1: [0, 0, 0, 0] â†’ [0, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:0.1 N2:0.1 N3:0.1 
  Computing hidden layer:
    H0: input=0.07 â†’ activation=0.06
    H1: input=0.25 â†’ activation=0.06
    H2: input=0.13 â†’ activation=0.06
    H3: input=0.25 â†’ activation=0.06
  Computing output layer:
    O0: input=0.02 â†’ activation=0.06
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 0]
  Output: [0.06, 0.06]
  Error: 0.125

  Updating weights...

Pattern 2: [1, 0, 1, 0] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:0.1 N2:1.0 N3:0.1 
  Computing hidden layer:
    H0: input=0.19 â†’ activation=0.06
    H1: input=2.12 â†’ activation=1.00
    H2: input=1.13 â†’ activation=1.00
    H3: input=2.12 â†’ activation=1.00
  Computing output layer:
    O0: input=0.19 â†’ activation=0.06
    O1: input=3.06 â†’ activation=1.00

  Target: [1, 0]
  Output: [0.06, 1.00]
  Error: 1.938

  Updating weights...
    â†‘ H0â†’O0 strengthened
    â†‘ H1â†’O0 strengthened
    â†‘ H2â†’O0 strengthened
    â†‘ H3â†’O0 strengthened
    â†“ H0â†’O1 weakened
    â†“ H1â†’O1 weakened
    â†“ H2â†’O1 weakened
    â†“ H3â†’O1 weakened

Pattern 3: [0, 1, 0, 1] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:1.0 N2:0.1 N3:1.0 
  Computing hidden layer:
    H0: input=1.07 â†’ activation=1.00
    H1: input=2.12 â†’ activation=1.00
    H2: input=1.13 â†’ activation=1.00
    H3: input=2.07 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [1, 0]
  Output: [1.00, 0.06]
  Error: 0.062

Pattern 4: [1, 1, 1, 1] â†’ [0, 1]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:1.0 N2:1.0 N3:1.0 
  Computing hidden layer:
    H0: input=1.19 â†’ activation=1.00
    H1: input=4.00 â†’ activation=1.00
    H2: input=2.12 â†’ activation=1.00
    H3: input=3.06 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 1]
  Output: [1.00, 0.06]
  Error: 1.938

  Updating weights...
    â†“ H0â†’O0 weakened
    â†“ H1â†’O0 weakened
    â†“ H2â†’O0 weakened
    â†“ H3â†’O0 weakened
    â†‘ H0â†’O1 strengthened
    â†‘ H1â†’O1 strengthened
    â†‘ H2â†’O1 strengthened
    â†‘ H3â†’O1 strengthened

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Epoch 8 Summary
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Average Error: 1.016
Learning Progress: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.0%

================================================================================
EPOCH 9
================================================================================

Pattern 1: [0, 0, 0, 0] â†’ [0, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:0.1 N2:0.1 N3:0.1 
  Computing hidden layer:
    H0: input=0.13 â†’ activation=0.06
    H1: input=0.25 â†’ activation=0.06
    H2: input=0.19 â†’ activation=0.06
    H3: input=0.13 â†’ activation=0.06
  Computing output layer:
    O0: input=0.02 â†’ activation=0.06
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 0]
  Output: [0.06, 0.06]
  Error: 0.125

  Updating weights...

Pattern 2: [1, 0, 1, 0] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:0.1 N2:1.0 N3:0.1 
  Computing hidden layer:
    H0: input=1.13 â†’ activation=1.00
    H1: input=2.12 â†’ activation=1.00
    H2: input=2.07 â†’ activation=1.00
    H3: input=0.25 â†’ activation=0.06
  Computing output layer:
    O0: input=0.19 â†’ activation=0.06
    O1: input=3.06 â†’ activation=1.00

  Target: [1, 0]
  Output: [0.06, 1.00]
  Error: 1.938

  Updating weights...
    â†‘ H0â†’O0 strengthened
    â†‘ H1â†’O0 strengthened
    â†‘ H2â†’O0 strengthened
    â†‘ H3â†’O0 strengthened
    â†“ H0â†’O1 weakened
    â†“ H1â†’O1 weakened
    â†“ H2â†’O1 weakened
    â†“ H3â†’O1 weakened

Pattern 3: [0, 1, 0, 1] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:1.0 N2:0.1 N3:1.0 
  Computing hidden layer:
    H0: input=1.13 â†’ activation=1.00
    H1: input=2.01 â†’ activation=1.00
    H2: input=1.13 â†’ activation=1.00
    H3: input=2.07 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [1, 0]
  Output: [1.00, 0.06]
  Error: 0.062

Pattern 4: [1, 1, 1, 1] â†’ [0, 1]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:1.0 N2:1.0 N3:1.0 
  Computing hidden layer:
    H0: input=2.12 â†’ activation=1.00
    H1: input=2.12 â†’ activation=1.00
    H2: input=2.12 â†’ activation=1.00
    H3: input=3.06 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 1]
  Output: [1.00, 0.06]
  Error: 1.938

  Updating weights...
    â†“ H0â†’O0 weakened
    â†“ H1â†’O0 weakened
    â†“ H2â†’O0 weakened
    â†“ H3â†’O0 weakened
    â†‘ H0â†’O1 strengthened
    â†‘ H1â†’O1 strengthened
    â†‘ H2â†’O1 strengthened
    â†‘ H3â†’O1 strengthened

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Epoch 9 Summary
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Average Error: 1.016
Learning Progress: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.0%

================================================================================
EPOCH 10
================================================================================

Pattern 1: [0, 0, 0, 0] â†’ [0, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:0.1 N2:0.1 N3:0.1 
  Computing hidden layer:
    H0: input=0.19 â†’ activation=0.06
    H1: input=0.25 â†’ activation=0.06
    H2: input=0.13 â†’ activation=0.06
    H3: input=0.19 â†’ activation=0.06
  Computing output layer:
    O0: input=0.02 â†’ activation=0.06
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 0]
  Output: [0.06, 0.06]
  Error: 0.125

  Updating weights...

Pattern 2: [1, 0, 1, 0] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:0.1 N2:1.0 N3:0.1 
  Computing hidden layer:
    H0: input=1.19 â†’ activation=1.00
    H1: input=2.12 â†’ activation=1.00
    H2: input=1.13 â†’ activation=1.00
    H3: input=2.07 â†’ activation=1.00
  Computing output layer:
    O0: input=0.25 â†’ activation=0.06
    O1: input=4.00 â†’ activation=1.00

  Target: [1, 0]
  Output: [0.06, 1.00]
  Error: 1.938

  Updating weights...
    â†‘ H0â†’O0 strengthened
    â†‘ H1â†’O0 strengthened
    â†‘ H2â†’O0 strengthened
    â†‘ H3â†’O0 strengthened
    â†“ H0â†’O1 weakened
    â†“ H1â†’O1 weakened
    â†“ H2â†’O1 weakened
    â†“ H3â†’O1 weakened

Pattern 3: [0, 1, 0, 1] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:1.0 N2:0.1 N3:1.0 
  Computing hidden layer:
    H0: input=2.07 â†’ activation=1.00
    H1: input=2.01 â†’ activation=1.00
    H2: input=1.13 â†’ activation=1.00
    H3: input=1.13 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [1, 0]
  Output: [1.00, 0.06]
  Error: 0.062

Pattern 4: [1, 1, 1, 1] â†’ [0, 1]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:1.0 N2:1.0 N3:1.0 
  Computing hidden layer:
    H0: input=3.06 â†’ activation=1.00
    H1: input=2.12 â†’ activation=1.00
    H2: input=2.12 â†’ activation=1.00
    H3: input=2.12 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 1]
  Output: [1.00, 0.06]
  Error: 1.938

  Updating weights...
    â†“ H0â†’O0 weakened
    â†“ H1â†’O0 weakened
    â†“ H2â†’O0 weakened
    â†“ H3â†’O0 weakened
    â†‘ H0â†’O1 strengthened
    â†‘ H1â†’O1 strengthened
    â†‘ H2â†’O1 strengthened
    â†‘ H3â†’O1 strengthened

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Epoch 10 Summary
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Average Error: 1.016
Learning Progress: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.0%

Network State Visualization:

     INPUT           HIDDEN          OUTPUT
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‰    â”‚
   â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‹    â”‚
   â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚         â”‚
   â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚         â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   â—‰ Active (>80%)  â— Partial (30-80%)  â—‹ Inactive (<30%)

================================================================================
EPOCH 11
================================================================================

Pattern 1: [0, 0, 0, 0] â†’ [0, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:0.1 N2:0.1 N3:0.1 
  Computing hidden layer:
    H0: input=0.25 â†’ activation=0.06
    H1: input=0.19 â†’ activation=0.06
    H2: input=0.19 â†’ activation=0.06
    H3: input=0.13 â†’ activation=0.06
  Computing output layer:
    O0: input=0.02 â†’ activation=0.06
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 0]
  Output: [0.06, 0.06]
  Error: 0.125

  Updating weights...

Pattern 2: [1, 0, 1, 0] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:0.1 N2:1.0 N3:0.1 
  Computing hidden layer:
    H0: input=2.12 â†’ activation=1.00
    H1: input=1.19 â†’ activation=1.00
    H2: input=2.07 â†’ activation=1.00
    H3: input=1.13 â†’ activation=1.00
  Computing output layer:
    O0: input=0.25 â†’ activation=0.06
    O1: input=4.00 â†’ activation=1.00

  Target: [1, 0]
  Output: [0.06, 1.00]
  Error: 1.938

  Updating weights...
    â†‘ H0â†’O0 strengthened
    â†‘ H1â†’O0 strengthened
    â†‘ H2â†’O0 strengthened
    â†‘ H3â†’O0 strengthened
    â†“ H0â†’O1 weakened
    â†“ H1â†’O1 weakened
    â†“ H2â†’O1 weakened
    â†“ H3â†’O1 weakened

Pattern 3: [0, 1, 0, 1] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:1.0 N2:0.1 N3:1.0 
  Computing hidden layer:
    H0: input=2.07 â†’ activation=1.00
    H1: input=2.01 â†’ activation=1.00
    H2: input=1.19 â†’ activation=1.00
    H3: input=1.13 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [1, 0]
  Output: [1.00, 0.06]
  Error: 0.062

Pattern 4: [1, 1, 1, 1] â†’ [0, 1]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:1.0 N2:1.0 N3:1.0 
  Computing hidden layer:
    H0: input=3.06 â†’ activation=1.00
    H1: input=2.12 â†’ activation=1.00
    H2: input=3.06 â†’ activation=1.00
    H3: input=2.12 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 1]
  Output: [1.00, 0.06]
  Error: 1.938

  Updating weights...
    â†“ H0â†’O0 weakened
    â†“ H1â†’O0 weakened
    â†“ H2â†’O0 weakened
    â†“ H3â†’O0 weakened
    â†‘ H0â†’O1 strengthened
    â†‘ H1â†’O1 strengthened
    â†‘ H2â†’O1 strengthened
    â†‘ H3â†’O1 strengthened

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Epoch 11 Summary
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Average Error: 1.016
Learning Progress: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.0%

================================================================================
EPOCH 12
================================================================================

Pattern 1: [0, 0, 0, 0] â†’ [0, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:0.1 N2:0.1 N3:0.1 
  Computing hidden layer:
    H0: input=0.19 â†’ activation=0.06
    H1: input=0.13 â†’ activation=0.06
    H2: input=0.07 â†’ activation=0.06
    H3: input=0.07 â†’ activation=0.06
  Computing output layer:
    O0: input=0.02 â†’ activation=0.06
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 0]
  Output: [0.06, 0.06]
  Error: 0.125

  Updating weights...

Pattern 2: [1, 0, 1, 0] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:0.1 N2:1.0 N3:0.1 
  Computing hidden layer:
    H0: input=1.19 â†’ activation=1.00
    H1: input=1.13 â†’ activation=1.00
    H2: input=0.19 â†’ activation=0.06
    H3: input=0.19 â†’ activation=0.06
  Computing output layer:
    O0: input=0.13 â†’ activation=0.06
    O1: input=2.12 â†’ activation=1.00

  Target: [1, 0]
  Output: [0.06, 1.00]
  Error: 1.938

  Updating weights...
    â†‘ H0â†’O0 strengthened
    â†‘ H1â†’O0 strengthened
    â†‘ H2â†’O0 strengthened
    â†‘ H3â†’O0 strengthened
    â†“ H0â†’O1 weakened
    â†“ H1â†’O1 weakened
    â†“ H2â†’O1 weakened
    â†“ H3â†’O1 weakened

Pattern 3: [0, 1, 0, 1] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:1.0 N2:0.1 N3:1.0 
  Computing hidden layer:
    H0: input=2.01 â†’ activation=1.00
    H1: input=1.13 â†’ activation=1.00
    H2: input=1.13 â†’ activation=1.00
    H3: input=1.07 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [1, 0]
  Output: [1.00, 0.06]
  Error: 0.062

Pattern 4: [1, 1, 1, 1] â†’ [0, 1]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:1.0 N2:1.0 N3:1.0 
  Computing hidden layer:
    H0: input=2.12 â†’ activation=1.00
    H1: input=2.12 â†’ activation=1.00
    H2: input=2.12 â†’ activation=1.00
    H3: input=1.19 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 1]
  Output: [1.00, 0.06]
  Error: 1.938

  Updating weights...
    â†“ H0â†’O0 weakened
    â†“ H1â†’O0 weakened
    â†“ H2â†’O0 weakened
    â†“ H3â†’O0 weakened
    â†‘ H0â†’O1 strengthened
    â†‘ H1â†’O1 strengthened
    â†‘ H2â†’O1 strengthened
    â†‘ H3â†’O1 strengthened

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Epoch 12 Summary
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Average Error: 1.016
Learning Progress: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.0%

================================================================================
EPOCH 13
================================================================================

Pattern 1: [0, 0, 0, 0] â†’ [0, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:0.1 N2:0.1 N3:0.1 
  Computing hidden layer:
    H0: input=0.13 â†’ activation=0.06
    H1: input=0.19 â†’ activation=0.06
    H2: input=0.13 â†’ activation=0.06
    H3: input=0.07 â†’ activation=0.06
  Computing output layer:
    O0: input=0.02 â†’ activation=0.06
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 0]
  Output: [0.06, 0.06]
  Error: 0.125

  Updating weights...

Pattern 2: [1, 0, 1, 0] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:0.1 N2:1.0 N3:0.1 
  Computing hidden layer:
    H0: input=0.25 â†’ activation=0.06
    H1: input=2.07 â†’ activation=1.00
    H2: input=1.13 â†’ activation=1.00
    H3: input=0.19 â†’ activation=0.06
  Computing output layer:
    O0: input=0.13 â†’ activation=0.06
    O1: input=2.12 â†’ activation=1.00

  Target: [1, 0]
  Output: [0.06, 1.00]
  Error: 1.938

  Updating weights...
    â†‘ H0â†’O0 strengthened
    â†‘ H1â†’O0 strengthened
    â†‘ H2â†’O0 strengthened
    â†‘ H3â†’O0 strengthened
    â†“ H0â†’O1 weakened
    â†“ H1â†’O1 weakened
    â†“ H2â†’O1 weakened
    â†“ H3â†’O1 weakened

Pattern 3: [0, 1, 0, 1] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:1.0 N2:0.1 N3:1.0 
  Computing hidden layer:
    H0: input=2.07 â†’ activation=1.00
    H1: input=1.13 â†’ activation=1.00
    H2: input=1.13 â†’ activation=1.00
    H3: input=1.13 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [1, 0]
  Output: [1.00, 0.06]
  Error: 0.062

Pattern 4: [1, 1, 1, 1] â†’ [0, 1]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:1.0 N2:1.0 N3:1.0 
  Computing hidden layer:
    H0: input=3.06 â†’ activation=1.00
    H1: input=2.12 â†’ activation=1.00
    H2: input=2.12 â†’ activation=1.00
    H3: input=2.12 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 1]
  Output: [1.00, 0.06]
  Error: 1.938

  Updating weights...
    â†“ H0â†’O0 weakened
    â†“ H1â†’O0 weakened
    â†“ H2â†’O0 weakened
    â†“ H3â†’O0 weakened
    â†‘ H0â†’O1 strengthened
    â†‘ H1â†’O1 strengthened
    â†‘ H2â†’O1 strengthened
    â†‘ H3â†’O1 strengthened

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Epoch 13 Summary
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Average Error: 1.016
Learning Progress: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.0%

================================================================================
EPOCH 14
================================================================================

Pattern 1: [0, 0, 0, 0] â†’ [0, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:0.1 N2:0.1 N3:0.1 
  Computing hidden layer:
    H0: input=0.19 â†’ activation=0.06
    H1: input=0.25 â†’ activation=0.06
    H2: input=0.13 â†’ activation=0.06
    H3: input=0.13 â†’ activation=0.06
  Computing output layer:
    O0: input=0.02 â†’ activation=0.06
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 0]
  Output: [0.06, 0.06]
  Error: 0.125

  Updating weights...

Pattern 2: [1, 0, 1, 0] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:0.1 N2:1.0 N3:0.1 
  Computing hidden layer:
    H0: input=1.19 â†’ activation=1.00
    H1: input=2.12 â†’ activation=1.00
    H2: input=1.13 â†’ activation=1.00
    H3: input=1.13 â†’ activation=1.00
  Computing output layer:
    O0: input=0.25 â†’ activation=0.06
    O1: input=4.00 â†’ activation=1.00

  Target: [1, 0]
  Output: [0.06, 1.00]
  Error: 1.938

  Updating weights...
    â†‘ H0â†’O0 strengthened
    â†‘ H1â†’O0 strengthened
    â†‘ H2â†’O0 strengthened
    â†‘ H3â†’O0 strengthened
    â†“ H0â†’O1 weakened
    â†“ H1â†’O1 weakened
    â†“ H2â†’O1 weakened
    â†“ H3â†’O1 weakened

Pattern 3: [0, 1, 0, 1] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:1.0 N2:0.1 N3:1.0 
  Computing hidden layer:
    H0: input=2.07 â†’ activation=1.00
    H1: input=2.07 â†’ activation=1.00
    H2: input=1.13 â†’ activation=1.00
    H3: input=1.19 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [1, 0]
  Output: [1.00, 0.06]
  Error: 0.062

Pattern 4: [1, 1, 1, 1] â†’ [0, 1]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:1.0 N2:1.0 N3:1.0 
  Computing hidden layer:
    H0: input=3.06 â†’ activation=1.00
    H1: input=3.06 â†’ activation=1.00
    H2: input=2.12 â†’ activation=1.00
    H3: input=3.06 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 1]
  Output: [1.00, 0.06]
  Error: 1.938

  Updating weights...
    â†“ H0â†’O0 weakened
    â†“ H1â†’O0 weakened
    â†“ H2â†’O0 weakened
    â†“ H3â†’O0 weakened
    â†‘ H0â†’O1 strengthened
    â†‘ H1â†’O1 strengthened
    â†‘ H2â†’O1 strengthened
    â†‘ H3â†’O1 strengthened

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Epoch 14 Summary
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Average Error: 1.016
Learning Progress: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.0%

================================================================================
EPOCH 15
================================================================================

Pattern 1: [0, 0, 0, 0] â†’ [0, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:0.1 N2:0.1 N3:0.1 
  Computing hidden layer:
    H0: input=0.13 â†’ activation=0.06
    H1: input=0.13 â†’ activation=0.06
    H2: input=0.25 â†’ activation=0.06
    H3: input=0.13 â†’ activation=0.06
  Computing output layer:
    O0: input=0.02 â†’ activation=0.06
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 0]
  Output: [0.06, 0.06]
  Error: 0.125

  Updating weights...

Pattern 2: [1, 0, 1, 0] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:0.1 N2:1.0 N3:0.1 
  Computing hidden layer:
    H0: input=1.13 â†’ activation=1.00
    H1: input=2.01 â†’ activation=1.00
    H2: input=2.12 â†’ activation=1.00
    H3: input=1.13 â†’ activation=1.00
  Computing output layer:
    O0: input=0.25 â†’ activation=0.06
    O1: input=4.00 â†’ activation=1.00

  Target: [1, 0]
  Output: [0.06, 1.00]
  Error: 1.938

  Updating weights...
    â†‘ H0â†’O0 strengthened
    â†‘ H1â†’O0 strengthened
    â†‘ H2â†’O0 strengthened
    â†‘ H3â†’O0 strengthened
    â†“ H0â†’O1 weakened
    â†“ H1â†’O1 weakened
    â†“ H2â†’O1 weakened
    â†“ H3â†’O1 weakened

Pattern 3: [0, 1, 0, 1] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:1.0 N2:0.1 N3:1.0 
  Computing hidden layer:
    H0: input=1.13 â†’ activation=1.00
    H1: input=0.19 â†’ activation=0.06
    H2: input=2.01 â†’ activation=1.00
    H3: input=1.07 â†’ activation=1.00
  Computing output layer:
    O0: input=3.06 â†’ activation=1.00
    O1: input=0.19 â†’ activation=0.06

  Target: [1, 0]
  Output: [1.00, 0.06]
  Error: 0.062

Pattern 4: [1, 1, 1, 1] â†’ [0, 1]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:1.0 N2:1.0 N3:1.0 
  Computing hidden layer:
    H0: input=2.12 â†’ activation=1.00
    H1: input=1.19 â†’ activation=1.00
    H2: input=2.12 â†’ activation=1.00
    H3: input=1.19 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 1]
  Output: [1.00, 0.06]
  Error: 1.938

  Updating weights...
    â†“ H0â†’O0 weakened
    â†“ H1â†’O0 weakened
    â†“ H2â†’O0 weakened
    â†“ H3â†’O0 weakened
    â†‘ H0â†’O1 strengthened
    â†‘ H1â†’O1 strengthened
    â†‘ H2â†’O1 strengthened
    â†‘ H3â†’O1 strengthened

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Epoch 15 Summary
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Average Error: 1.016
Learning Progress: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.0%

Network State Visualization:

     INPUT           HIDDEN          OUTPUT
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‰    â”‚
   â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‹    â”‚
   â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚         â”‚
   â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚         â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   â—‰ Active (>80%)  â— Partial (30-80%)  â—‹ Inactive (<30%)

================================================================================
EPOCH 16
================================================================================

Pattern 1: [0, 0, 0, 0] â†’ [0, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:0.1 N2:0.1 N3:0.1 
  Computing hidden layer:
    H0: input=0.07 â†’ activation=0.06
    H1: input=0.07 â†’ activation=0.06
    H2: input=0.19 â†’ activation=0.06
    H3: input=0.19 â†’ activation=0.06
  Computing output layer:
    O0: input=0.02 â†’ activation=0.06
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 0]
  Output: [0.06, 0.06]
  Error: 0.125

  Updating weights...

Pattern 2: [1, 0, 1, 0] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:0.1 N2:1.0 N3:0.1 
  Computing hidden layer:
    H0: input=0.19 â†’ activation=0.06
    H1: input=1.07 â†’ activation=1.00
    H2: input=2.07 â†’ activation=1.00
    H3: input=1.19 â†’ activation=1.00
  Computing output layer:
    O0: input=0.19 â†’ activation=0.06
    O1: input=3.06 â†’ activation=1.00

  Target: [1, 0]
  Output: [0.06, 1.00]
  Error: 1.938

  Updating weights...
    â†‘ H0â†’O0 strengthened
    â†‘ H1â†’O0 strengthened
    â†‘ H2â†’O0 strengthened
    â†‘ H3â†’O0 strengthened
    â†“ H0â†’O1 weakened
    â†“ H1â†’O1 weakened
    â†“ H2â†’O1 weakened
    â†“ H3â†’O1 weakened

Pattern 3: [0, 1, 0, 1] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:1.0 N2:0.1 N3:1.0 
  Computing hidden layer:
    H0: input=1.07 â†’ activation=1.00
    H1: input=0.13 â†’ activation=0.06
    H2: input=1.13 â†’ activation=1.00
    H3: input=2.07 â†’ activation=1.00
  Computing output layer:
    O0: input=3.06 â†’ activation=1.00
    O1: input=0.19 â†’ activation=0.06

  Target: [1, 0]
  Output: [1.00, 0.06]
  Error: 0.062

Pattern 4: [1, 1, 1, 1] â†’ [0, 1]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:1.0 N2:1.0 N3:1.0 
  Computing hidden layer:
    H0: input=1.19 â†’ activation=1.00
    H1: input=0.25 â†’ activation=0.06
    H2: input=2.12 â†’ activation=1.00
    H3: input=3.06 â†’ activation=1.00
  Computing output layer:
    O0: input=3.06 â†’ activation=1.00
    O1: input=0.19 â†’ activation=0.06

  Target: [0, 1]
  Output: [1.00, 0.06]
  Error: 1.938

  Updating weights...
    â†“ H0â†’O0 weakened
    â†“ H1â†’O0 weakened
    â†“ H2â†’O0 weakened
    â†“ H3â†’O0 weakened
    â†‘ H0â†’O1 strengthened
    â†‘ H1â†’O1 strengthened
    â†‘ H2â†’O1 strengthened
    â†‘ H3â†’O1 strengthened

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Epoch 16 Summary
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Average Error: 1.016
Learning Progress: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.0%

================================================================================
EPOCH 17
================================================================================

Pattern 1: [0, 0, 0, 0] â†’ [0, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:0.1 N2:0.1 N3:0.1 
  Computing hidden layer:
    H0: input=0.07 â†’ activation=0.06
    H1: input=0.19 â†’ activation=0.06
    H2: input=0.19 â†’ activation=0.06
    H3: input=0.13 â†’ activation=0.06
  Computing output layer:
    O0: input=0.02 â†’ activation=0.06
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 0]
  Output: [0.06, 0.06]
  Error: 0.125

  Updating weights...

Pattern 2: [1, 0, 1, 0] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:0.1 N2:1.0 N3:0.1 
  Computing hidden layer:
    H0: input=1.07 â†’ activation=1.00
    H1: input=2.07 â†’ activation=1.00
    H2: input=2.07 â†’ activation=1.00
    H3: input=1.13 â†’ activation=1.00
  Computing output layer:
    O0: input=0.25 â†’ activation=0.06
    O1: input=4.00 â†’ activation=1.00

  Target: [1, 0]
  Output: [0.06, 1.00]
  Error: 1.938

  Updating weights...
    â†‘ H0â†’O0 strengthened
    â†‘ H1â†’O0 strengthened
    â†‘ H2â†’O0 strengthened
    â†‘ H3â†’O0 strengthened
    â†“ H0â†’O1 weakened
    â†“ H1â†’O1 weakened
    â†“ H2â†’O1 weakened
    â†“ H3â†’O1 weakened

Pattern 3: [0, 1, 0, 1] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:1.0 N2:0.1 N3:1.0 
  Computing hidden layer:
    H0: input=0.19 â†’ activation=0.06
    H1: input=1.19 â†’ activation=1.00
    H2: input=1.19 â†’ activation=1.00
    H3: input=1.13 â†’ activation=1.00
  Computing output layer:
    O0: input=3.06 â†’ activation=1.00
    O1: input=0.19 â†’ activation=0.06

  Target: [1, 0]
  Output: [1.00, 0.06]
  Error: 0.062

Pattern 4: [1, 1, 1, 1] â†’ [0, 1]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:1.0 N2:1.0 N3:1.0 
  Computing hidden layer:
    H0: input=1.19 â†’ activation=1.00
    H1: input=3.06 â†’ activation=1.00
    H2: input=3.06 â†’ activation=1.00
    H3: input=2.12 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 1]
  Output: [1.00, 0.06]
  Error: 1.938

  Updating weights...
    â†“ H0â†’O0 weakened
    â†“ H1â†’O0 weakened
    â†“ H2â†’O0 weakened
    â†“ H3â†’O0 weakened
    â†‘ H0â†’O1 strengthened
    â†‘ H1â†’O1 strengthened
    â†‘ H2â†’O1 strengthened
    â†‘ H3â†’O1 strengthened

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Epoch 17 Summary
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Average Error: 1.016
Learning Progress: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.0%

================================================================================
EPOCH 18
================================================================================

Pattern 1: [0, 0, 0, 0] â†’ [0, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:0.1 N2:0.1 N3:0.1 
  Computing hidden layer:
    H0: input=0.19 â†’ activation=0.06
    H1: input=0.19 â†’ activation=0.06
    H2: input=0.25 â†’ activation=0.06
    H3: input=0.19 â†’ activation=0.06
  Computing output layer:
    O0: input=0.02 â†’ activation=0.06
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 0]
  Output: [0.06, 0.06]
  Error: 0.125

  Updating weights...

Pattern 2: [1, 0, 1, 0] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:0.1 N2:1.0 N3:0.1 
  Computing hidden layer:
    H0: input=1.19 â†’ activation=1.00
    H1: input=2.07 â†’ activation=1.00
    H2: input=2.12 â†’ activation=1.00
    H3: input=1.19 â†’ activation=1.00
  Computing output layer:
    O0: input=0.25 â†’ activation=0.06
    O1: input=4.00 â†’ activation=1.00

  Target: [1, 0]
  Output: [0.06, 1.00]
  Error: 1.938

  Updating weights...
    â†‘ H0â†’O0 strengthened
    â†‘ H1â†’O0 strengthened
    â†‘ H2â†’O0 strengthened
    â†‘ H3â†’O0 strengthened
    â†“ H0â†’O1 weakened
    â†“ H1â†’O1 weakened
    â†“ H2â†’O1 weakened
    â†“ H3â†’O1 weakened

Pattern 3: [0, 1, 0, 1] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:1.0 N2:0.1 N3:1.0 
  Computing hidden layer:
    H0: input=2.07 â†’ activation=1.00
    H1: input=1.13 â†’ activation=1.00
    H2: input=2.07 â†’ activation=1.00
    H3: input=2.01 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [1, 0]
  Output: [1.00, 0.06]
  Error: 0.062

Pattern 4: [1, 1, 1, 1] â†’ [0, 1]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:1.0 N2:1.0 N3:1.0 
  Computing hidden layer:
    H0: input=3.06 â†’ activation=1.00
    H1: input=2.12 â†’ activation=1.00
    H2: input=3.06 â†’ activation=1.00
    H3: input=2.12 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 1]
  Output: [1.00, 0.06]
  Error: 1.938

  Updating weights...
    â†“ H0â†’O0 weakened
    â†“ H1â†’O0 weakened
    â†“ H2â†’O0 weakened
    â†“ H3â†’O0 weakened
    â†‘ H0â†’O1 strengthened
    â†‘ H1â†’O1 strengthened
    â†‘ H2â†’O1 strengthened
    â†‘ H3â†’O1 strengthened

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Epoch 18 Summary
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Average Error: 1.016
Learning Progress: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.0%

================================================================================
EPOCH 19
================================================================================

Pattern 1: [0, 0, 0, 0] â†’ [0, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:0.1 N2:0.1 N3:0.1 
  Computing hidden layer:
    H0: input=0.25 â†’ activation=0.06
    H1: input=0.25 â†’ activation=0.06
    H2: input=0.19 â†’ activation=0.06
    H3: input=0.19 â†’ activation=0.06
  Computing output layer:
    O0: input=0.02 â†’ activation=0.06
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 0]
  Output: [0.06, 0.06]
  Error: 0.125

  Updating weights...

Pattern 2: [1, 0, 1, 0] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:0.1 N2:1.0 N3:0.1 
  Computing hidden layer:
    H0: input=2.12 â†’ activation=1.00
    H1: input=2.12 â†’ activation=1.00
    H2: input=1.19 â†’ activation=1.00
    H3: input=2.07 â†’ activation=1.00
  Computing output layer:
    O0: input=0.25 â†’ activation=0.06
    O1: input=4.00 â†’ activation=1.00

  Target: [1, 0]
  Output: [0.06, 1.00]
  Error: 1.938

  Updating weights...
    â†‘ H0â†’O0 strengthened
    â†‘ H1â†’O0 strengthened
    â†‘ H2â†’O0 strengthened
    â†‘ H3â†’O0 strengthened
    â†“ H0â†’O1 weakened
    â†“ H1â†’O1 weakened
    â†“ H2â†’O1 weakened
    â†“ H3â†’O1 weakened

Pattern 3: [0, 1, 0, 1] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:1.0 N2:0.1 N3:1.0 
  Computing hidden layer:
    H0: input=2.07 â†’ activation=1.00
    H1: input=2.07 â†’ activation=1.00
    H2: input=2.07 â†’ activation=1.00
    H3: input=1.13 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [1, 0]
  Output: [1.00, 0.06]
  Error: 0.062

Pattern 4: [1, 1, 1, 1] â†’ [0, 1]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:1.0 N2:1.0 N3:1.0 
  Computing hidden layer:
    H0: input=3.06 â†’ activation=1.00
    H1: input=3.06 â†’ activation=1.00
    H2: input=3.06 â†’ activation=1.00
    H3: input=2.12 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 1]
  Output: [1.00, 0.06]
  Error: 1.938

  Updating weights...
    â†“ H0â†’O0 weakened
    â†“ H1â†’O0 weakened
    â†“ H2â†’O0 weakened
    â†“ H3â†’O0 weakened
    â†‘ H0â†’O1 strengthened
    â†‘ H1â†’O1 strengthened
    â†‘ H2â†’O1 strengthened
    â†‘ H3â†’O1 strengthened

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Epoch 19 Summary
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Average Error: 1.016
Learning Progress: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.0%

================================================================================
EPOCH 20
================================================================================

Pattern 1: [0, 0, 0, 0] â†’ [0, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:0.1 N2:0.1 N3:0.1 
  Computing hidden layer:
    H0: input=0.19 â†’ activation=0.06
    H1: input=0.07 â†’ activation=0.06
    H2: input=0.13 â†’ activation=0.06
    H3: input=0.19 â†’ activation=0.06
  Computing output layer:
    O0: input=0.02 â†’ activation=0.06
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 0]
  Output: [0.06, 0.06]
  Error: 0.125

  Updating weights...

Pattern 2: [1, 0, 1, 0] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:0.1 N2:1.0 N3:0.1 
  Computing hidden layer:
    H0: input=2.07 â†’ activation=1.00
    H1: input=0.19 â†’ activation=0.06
    H2: input=1.13 â†’ activation=1.00
    H3: input=1.19 â†’ activation=1.00
  Computing output layer:
    O0: input=0.19 â†’ activation=0.06
    O1: input=3.06 â†’ activation=1.00

  Target: [1, 0]
  Output: [0.06, 1.00]
  Error: 1.938

  Updating weights...
    â†‘ H0â†’O0 strengthened
    â†‘ H1â†’O0 strengthened
    â†‘ H2â†’O0 strengthened
    â†‘ H3â†’O0 strengthened
    â†“ H0â†’O1 weakened
    â†“ H1â†’O1 weakened
    â†“ H2â†’O1 weakened
    â†“ H3â†’O1 weakened

Pattern 3: [0, 1, 0, 1] â†’ [1, 0]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:1.0 N2:0.1 N3:1.0 
  Computing hidden layer:
    H0: input=1.13 â†’ activation=1.00
    H1: input=1.07 â†’ activation=1.00
    H2: input=1.13 â†’ activation=1.00
    H3: input=2.07 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [1, 0]
  Output: [1.00, 0.06]
  Error: 0.062

Pattern 4: [1, 1, 1, 1] â†’ [0, 1]

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:1.0 N2:1.0 N3:1.0 
  Computing hidden layer:
    H0: input=2.12 â†’ activation=1.00
    H1: input=1.19 â†’ activation=1.00
    H2: input=2.12 â†’ activation=1.00
    H3: input=3.06 â†’ activation=1.00
  Computing output layer:
    O0: input=4.00 â†’ activation=1.00
    O1: input=0.25 â†’ activation=0.06

  Target: [0, 1]
  Output: [1.00, 0.06]
  Error: 1.938

  Updating weights...
    â†“ H0â†’O0 weakened
    â†“ H1â†’O0 weakened
    â†“ H2â†’O0 weakened
    â†“ H3â†’O0 weakened
    â†‘ H0â†’O1 strengthened
    â†‘ H1â†’O1 strengthened
    â†‘ H2â†’O1 strengthened
    â†‘ H3â†’O1 strengthened

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Epoch 20 Summary
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Average Error: 1.016
Learning Progress: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0.0%

Network State Visualization:

     INPUT           HIDDEN          OUTPUT
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‰    â”‚
   â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‹    â”‚
   â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚         â”‚
   â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚         â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   â—‰ Active (>80%)  â— Partial (30-80%)  â—‹ Inactive (<30%)

================================================================================
TESTING TRAINED NETWORK
================================================================================

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:0.1 N2:0.1 N3:0.1 
  Computing hidden layer:
    H0: input=0.25 â†’ activation=0.06
    H1: input=0.13 â†’ activation=0.06
    H2: input=0.19 â†’ activation=0.06
    H3: input=0.13 â†’ activation=0.06
  Computing output layer:
    O0: input=0.02 â†’ activation=0.06
    O1: input=0.25 â†’ activation=0.06

Input: [0, 0, 0, 0]
Target: [0, 0]
Output: [0, 0] (raw: [0.06, 0.06])
âœ“ Correct!

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:0.1 N2:1.0 N3:0.1 
  Computing hidden layer:
    H0: input=2.12 â†’ activation=1.00
    H1: input=0.25 â†’ activation=0.06
    H2: input=1.19 â†’ activation=1.00
    H3: input=1.13 â†’ activation=1.00
  Computing output layer:
    O0: input=0.19 â†’ activation=0.06
    O1: input=3.06 â†’ activation=1.00

Input: [1, 0, 1, 0]
Target: [1, 0]
Output: [0, 1] (raw: [0.06, 1.00])
âœ— Incorrect

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:0.1 N1:1.0 N2:0.1 N3:1.0 
  Computing hidden layer:
    H0: input=2.12 â†’ activation=1.00
    H1: input=2.01 â†’ activation=1.00
    H2: input=2.07 â†’ activation=1.00
    H3: input=1.13 â†’ activation=1.00
  Computing output layer:
    O0: input=0.25 â†’ activation=0.06
    O1: input=4.00 â†’ activation=1.00

Input: [0, 1, 0, 1]
Target: [1, 0]
Output: [0, 1] (raw: [0.06, 1.00])
âœ— Incorrect

â†’ Forward Pass
  Clearing neurons... âœ“
  Setting inputs: N0:1.0 N1:1.0 N2:1.0 N3:1.0 
  Computing hidden layer:
    H0: input=4.00 â†’ activation=1.00
    H1: input=2.12 â†’ activation=1.00
    H2: input=3.06 â†’ activation=1.00
    H3: input=2.12 â†’ activation=1.00
  Computing output layer:
    O0: input=0.25 â†’ activation=0.06
    O1: input=4.00 â†’ activation=1.00

Input: [1, 1, 1, 1]
Target: [0, 1]
Output: [0, 1] (raw: [0.06, 1.00])
âœ“ Correct!

Accuracy: 50.0% (2/4)

Network State Visualization:

     INPUT           HIDDEN          OUTPUT
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‹    â”‚
   â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‰    â”‚
   â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚         â”‚
   â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚    â—‰    â”‚  â•â•â•ªâ•â•  â”‚         â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   â—‰ Active (>80%)  â— Partial (30-80%)  â—‹ Inactive (<30%)

âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ 
Training Complete! Your DRAM has learned!
âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ âœ¨ 

ğŸ”Œ Serial port closed

